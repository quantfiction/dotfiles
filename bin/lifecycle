#!/usr/bin/env python3
"""
Lifecycle Orchestrator

Drives a project through the complete planning → review → implementation pipeline:

  Phase 1: Author   (intake → research → plan-polish → write-beads)
  Phase 2: Design Review Loop (review-design ↔ plan-polish revise)
  Phase 3: Bead Review Loop   (bead-review ↔ bead-fix)
  Phase 4: Crystallize        (create-beads)
  Phase 5: Implement          (DAG-aware parallel with worker subagents)

Usage:
  lifecycle <path-to-ROUGH.md> [--skip-to <phase>] [--dry-run] [--max-workers N]
  lifecycle docs/plans/my-feature/ROUGH.md
  lifecycle docs/plans/my-feature/ROUGH.md --skip-to implement
"""

import argparse
import json
import os
import re
import subprocess
import sys
import time
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Optional


# ─── Constants ───────────────────────────────────────────────────────────────

MAX_DESIGN_REVIEW_ITERATIONS = 5
MAX_BEAD_REVIEW_ITERATIONS = 5
MAX_BEAD_RETRIES = 3
DEFAULT_MAX_WORKERS = 4

VERDICT_APPROVED = "APPROVED_FOR_DECOMPOSITION"
VERDICT_REVISE = "REVISE_AND_RESUBMIT"
BEAD_APPROVED = "APPROVED"


# ─── Data types ──────────────────────────────────────────────────────────────

class Phase(str, Enum):
    AUTHOR = "author"
    DESIGN_REVIEW = "design-review"
    BEAD_REVIEW = "bead-review"
    CRYSTALLIZE = "crystallize"
    IMPLEMENT = "implement"


@dataclass
class IntakeResult:
    track: str  # S, M, L
    research_mode: str  # none, targeted, deep
    review_mode: str  # none, lite, full


@dataclass
class ProjectContext:
    rough_path: Path
    project_dir: Path
    project_slug: str
    cwd: Path

    @property
    def intake_path(self) -> Path:
        return self.project_dir / "INTAKE.md"

    @property
    def research_path(self) -> Path:
        return self.project_dir / "RESEARCH_DOSSIER.md"

    @property
    def tdd_path(self) -> Path:
        return self.project_dir / "TECHNICAL_DESIGN.md"

    @property
    def design_review_path(self) -> Path:
        return self.project_dir / "DESIGN_REVIEW.md"

    @property
    def design_ledger_path(self) -> Path:
        return self.project_dir / "DESIGN_LEDGER.md"

    @property
    def beads_path(self) -> Path:
        return self.project_dir / "BEADS.md"

    @property
    def beads_ledger_path(self) -> Path:
        return self.project_dir / "BEADS_LEDGER.md"


# ─── Logging ─────────────────────────────────────────────────────────────────

class Colors:
    GREEN = "\033[0;32m"
    YELLOW = "\033[1;33m"
    RED = "\033[0;31m"
    BLUE = "\033[0;34m"
    CYAN = "\033[0;36m"
    BOLD = "\033[1m"
    NC = "\033[0m"


def log_phase(msg: str):
    print(f"\n{Colors.BOLD}{Colors.CYAN}{'═' * 60}{Colors.NC}")
    print(f"{Colors.BOLD}{Colors.CYAN}  {msg}{Colors.NC}")
    print(f"{Colors.BOLD}{Colors.CYAN}{'═' * 60}{Colors.NC}\n")


def log_step(msg: str):
    print(f"{Colors.GREEN}[+]{Colors.NC} {msg}")


def log_warn(msg: str):
    print(f"{Colors.YELLOW}[!]{Colors.NC} {msg}")


def log_error(msg: str):
    print(f"{Colors.RED}[✗]{Colors.NC} {msg}", file=sys.stderr)


def log_info(msg: str):
    print(f"{Colors.BLUE}[i]{Colors.NC} {msg}")


# ─── RPC Client ──────────────────────────────────────────────────────────────

class PiRpcSession:
    """Manages a long-lived pi session via RPC mode for multi-turn conversations."""

    def __init__(self, cwd: str, session_name: Optional[str] = None, model: Optional[str] = None):
        self.cwd = cwd
        self.proc: Optional[subprocess.Popen] = None
        self.session_name = session_name
        self.model = model
        self._req_counter = 0

    def start(self):
        cmd = ["pi", "--mode", "rpc"]
        if self.model:
            cmd.extend(["--model", self.model])
        log_info(f"Starting RPC session: {' '.join(cmd)}")
        self.proc = subprocess.Popen(
            cmd,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            cwd=self.cwd,
        )
        # Set session name if provided
        if self.session_name:
            self._send_command({"type": "set_session_name", "name": self.session_name})

    def _next_id(self) -> str:
        self._req_counter += 1
        return f"req-{self._req_counter}"

    def _send_command(self, cmd: dict) -> dict:
        if not self.proc or self.proc.poll() is not None:
            raise RuntimeError("RPC session is not running")

        req_id = self._next_id()
        cmd["id"] = req_id
        line = json.dumps(cmd) + "\n"
        self.proc.stdin.write(line)
        self.proc.stdin.flush()

        # Read until we get the response with matching id
        while True:
            resp_line = self.proc.stdout.readline()
            if not resp_line:
                raise RuntimeError("RPC session closed unexpectedly")
            try:
                event = json.loads(resp_line.strip())
            except json.JSONDecodeError:
                continue
            if event.get("type") == "response" and event.get("id") == req_id:
                return event

        return {}  # unreachable

    def prompt(self, message: str, wait: bool = True) -> list[dict]:
        """Send a prompt and wait for agent_end. Returns all generated messages."""
        if not self.proc or self.proc.poll() is not None:
            raise RuntimeError("RPC session is not running")

        req_id = self._next_id()
        cmd = {"id": req_id, "type": "prompt", "message": message}
        self.proc.stdin.write(json.dumps(cmd) + "\n")
        self.proc.stdin.flush()

        messages = []
        got_response = False
        got_agent_end = False

        while True:
            line = self.proc.stdout.readline()
            if not line:
                raise RuntimeError("RPC session closed unexpectedly")
            try:
                event = json.loads(line.strip())
            except json.JSONDecodeError:
                continue

            event_type = event.get("type", "")

            # Handle the prompt response (acknowledgment)
            if event_type == "response" and event.get("id") == req_id:
                got_response = True
                if not event.get("success"):
                    raise RuntimeError(f"Prompt failed: {event.get('error')}")
                if not wait:
                    return []

            # Stream text deltas for visibility
            if event_type == "message_update":
                delta_event = event.get("assistantMessageEvent", {})
                if delta_event.get("type") == "text_delta":
                    print(delta_event.get("delta", ""), end="", flush=True)

            # Handle extension UI requests (auto-confirm)
            if event_type == "extension_ui_request":
                self._handle_ui_request(event)

            # Agent finished
            if event_type == "agent_end":
                messages = event.get("messages", [])
                got_agent_end = True
                print()  # newline after streaming
                break

        return messages

    def _handle_ui_request(self, event: dict):
        """Auto-respond to extension UI dialog requests."""
        method = event.get("method", "")
        req_id = event.get("id")

        if not req_id:
            return  # fire-and-forget

        if method == "confirm":
            resp = {"type": "extension_ui_response", "id": req_id, "confirmed": True}
        elif method == "select":
            options = event.get("options", [])
            resp = {"type": "extension_ui_response", "id": req_id, "value": options[0] if options else None}
        elif method == "input":
            resp = {"type": "extension_ui_response", "id": req_id, "value": ""}
        else:
            return  # fire-and-forget methods

        self.proc.stdin.write(json.dumps(resp) + "\n")
        self.proc.stdin.flush()

    def stop(self):
        if self.proc and self.proc.poll() is None:
            self.proc.stdin.close()
            self.proc.wait(timeout=10)


# ─── One-shot pi execution ──────────────────────────────────────────────────

def pi_oneshot(prompt: str, cwd: str, model: Optional[str] = None) -> str:
    """Run a single pi -p --no-session command and return stdout."""
    cmd = ["pi", "-p", "--no-session"]
    if model:
        cmd.extend(["--model", model])
    cmd.append(prompt)

    log_info(f"Running one-shot: pi -p --no-session ...")
    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        cwd=cwd,
    )
    if result.returncode != 0:
        log_error(f"pi exited with code {result.returncode}")
        if result.stderr:
            log_error(result.stderr[:500])
    return result.stdout


# ─── Verdict Parsing ─────────────────────────────────────────────────────────

def parse_design_verdict(ctx: ProjectContext) -> str:
    """Parse the design review verdict from DESIGN_REVIEW.md."""
    path = ctx.design_review_path
    if not path.exists():
        log_error(f"DESIGN_REVIEW.md not found at {path}")
        return "MISSING"

    content = path.read_text()

    # Look for the verdict line — it appears as a bold line or heading
    if VERDICT_APPROVED in content:
        return VERDICT_APPROVED
    if VERDICT_REVISE in content:
        return VERDICT_REVISE

    log_warn("Could not parse verdict from DESIGN_REVIEW.md")
    return "UNKNOWN"


def parse_bead_verdict(ctx: ProjectContext) -> str:
    """Parse the bead review verdict. Returns 'APPROVED' or 'HAS_FINDINGS'."""
    # Check BEADS_LEDGER.md for open blockers
    ledger_path = ctx.beads_ledger_path
    if not ledger_path.exists():
        log_warn("BEADS_LEDGER.md not found — assuming not reviewed yet")
        return "MISSING"

    content = ledger_path.read_text()

    # Check for APPROVED verdict in the latest pass
    if re.search(r"^#+\s*Verdict.*\n+\s*APPROVED", content, re.MULTILINE):
        return BEAD_APPROVED

    # Check for any OPEN blockers
    if re.search(r"Status:\s*OPEN", content) and re.search(r"Severity:\s*blocker", content, re.IGNORECASE):
        return "HAS_BLOCKERS"

    if re.search(r"Status:\s*OPEN", content):
        return "HAS_FINDINGS"

    # No open issues
    return BEAD_APPROVED


def parse_intake(ctx: ProjectContext) -> IntakeResult:
    """Parse INTAKE.md to extract track, research mode, and review mode."""
    path = ctx.intake_path
    if not path.exists():
        raise FileNotFoundError(f"INTAKE.md not found at {path}")

    content = path.read_text()

    # Parse track
    track_match = re.search(r"track:\s*([SML])", content, re.IGNORECASE)
    track = track_match.group(1).upper() if track_match else "M"

    # Parse research mode
    research_match = re.search(r"researchMode:\s*(\w+)", content)
    research_mode = research_match.group(1) if research_match else "none"

    # Parse review mode
    review_match = re.search(r"reviewMode:\s*(\w+)", content)
    review_mode = review_match.group(1) if review_match else "none"

    # Infer from track if not explicitly set
    if track == "L":
        research_mode = research_mode if research_mode != "none" else "deep"
        review_mode = "full"
    elif track == "S":
        research_mode = "none"
        review_mode = "none"

    return IntakeResult(track=track, research_mode=research_mode, review_mode=review_mode)


# ─── Phase Implementations ───────────────────────────────────────────────────

def phase_author(ctx: ProjectContext, rpc: PiRpcSession, dry_run: bool = False):
    """Phase 1: Author — intake → research → plan-polish → write-beads."""
    log_phase("Phase 1: Author")

    # Step 1: Intake
    log_step("Running /intake")
    if dry_run:
        log_info("[dry-run] Would run intake")
    else:
        rpc.prompt(
            f"Load the /intake skill. Run intake on the rough plan at {ctx.rough_path}. "
            f"The project slug is '{ctx.project_slug}'. "
            f"Write INTAKE.md to {ctx.project_dir}/INTAKE.md"
        )

    if not ctx.intake_path.exists() and not dry_run:
        raise RuntimeError("Intake did not produce INTAKE.md")

    if dry_run:
        return

    intake = parse_intake(ctx)
    log_info(f"Track: {intake.track}, Research: {intake.research_mode}, Review: {intake.review_mode}")

    # Track S: skip planning, just implement
    if intake.track == "S":
        log_warn("Track S — skipping full planning lifecycle. Implement directly.")
        return

    # Step 2: Research (if needed)
    if intake.research_mode != "none":
        log_step(f"Running /research-plan (mode: {intake.research_mode})")
        rpc.prompt(
            f"Load the /research-plan skill. Run research for project '{ctx.project_slug}' "
            f"with mode '{intake.research_mode}'. INTAKE.md is at {ctx.intake_path}. "
            f"Write RESEARCH_DOSSIER.md to {ctx.project_dir}/RESEARCH_DOSSIER.md"
        )
    else:
        log_info("Skipping research (researchMode: none)")

    # Step 3: Plan Polish
    log_step("Running /plan-polish")
    rpc.prompt(
        f"Load the /plan-polish skill. Create a Technical Design Document for project "
        f"'{ctx.project_slug}'. INTAKE.md is at {ctx.intake_path}. "
        f"The rough plan is at {ctx.rough_path}. "
        + (f"RESEARCH_DOSSIER.md is at {ctx.research_path}. " if intake.research_mode != "none" else "")
        + f"Write TECHNICAL_DESIGN.md to {ctx.tdd_path}"
    )

    if not ctx.tdd_path.exists():
        raise RuntimeError("Plan polish did not produce TECHNICAL_DESIGN.md")


def phase_design_review(ctx: ProjectContext, rpc: PiRpcSession, dry_run: bool = False):
    """Phase 2: Design Review Loop."""
    log_phase("Phase 2: Design Review")

    # Check if review is needed
    if not ctx.intake_path.exists():
        if dry_run:
            log_info("[dry-run] INTAKE.md not yet created — assuming review needed")
            lite_flag = ""
        else:
            raise FileNotFoundError(f"INTAKE.md not found at {ctx.intake_path}")
    else:
        intake = parse_intake(ctx)
        if intake.review_mode == "none":
            log_info("Review mode is 'none' — skipping design review")
            return
        lite_flag = "--lite" if intake.review_mode == "lite" else ""

    for iteration in range(1, MAX_DESIGN_REVIEW_ITERATIONS + 1):
        log_step(f"Design review iteration {iteration}/{MAX_DESIGN_REVIEW_ITERATIONS}")

        if dry_run:
            log_info("[dry-run] Would run review-design in fresh session")
            return

        # Fresh session for review (unbiased)
        review_prompt = (
            f"Load the /review-design skill. "
            f"{'Use lite review mode. ' if lite_flag else ''}"
            f"Review the TDD at {ctx.tdd_path}. "
            f"The project slug is '{ctx.project_slug}'. "
            f"Write DESIGN_REVIEW.md to {ctx.design_review_path} "
            f"and update DESIGN_LEDGER.md at {ctx.design_ledger_path}"
        )
        pi_oneshot(review_prompt, cwd=str(ctx.cwd))

        # Parse verdict
        verdict = parse_design_verdict(ctx)
        log_info(f"Verdict: {verdict}")

        if verdict == VERDICT_APPROVED:
            log_step("Design approved! ✓")
            return

        if verdict == VERDICT_REVISE:
            log_warn(f"Revision needed (iteration {iteration})")

            if iteration >= MAX_DESIGN_REVIEW_ITERATIONS:
                log_error(f"Max design review iterations ({MAX_DESIGN_REVIEW_ITERATIONS}) reached. Aborting.")
                sys.exit(1)

            # Revise using the author session (warm context)
            log_step("Running /plan-polish in revision mode")
            rpc.prompt(
                f"Load the /plan-polish skill. "
                f"DESIGN_REVIEW.md at {ctx.design_review_path} has verdict REVISE_AND_RESUBMIT. "
                f"Read the Required Revisions section and the DESIGN_LEDGER.md at {ctx.design_ledger_path}. "
                f"Revise TECHNICAL_DESIGN.md at {ctx.tdd_path} to address all required revisions. "
                f"Do NOT re-create the file from scratch — apply targeted fixes."
            )
        else:
            log_error(f"Unexpected verdict: {verdict}")
            sys.exit(1)

    log_error("Design review loop did not converge")
    sys.exit(1)


def phase_write_beads(ctx: ProjectContext, rpc: PiRpcSession, dry_run: bool = False):
    """Write beads (runs in author session after design approval)."""
    log_step("Running /write-beads")

    if dry_run:
        log_info("[dry-run] Would run write-beads")
        return

    rpc.prompt(
        f"Load the /write-beads skill. Decompose the approved TDD at {ctx.tdd_path} "
        f"into beads. The project slug is '{ctx.project_slug}'. "
        f"Write BEADS.md to {ctx.beads_path}"
    )

    if not ctx.beads_path.exists():
        raise RuntimeError("write-beads did not produce BEADS.md")


def phase_bead_review(ctx: ProjectContext, rpc: PiRpcSession, dry_run: bool = False):
    """Phase 3: Bead Review Loop."""
    log_phase("Phase 3: Bead Review")

    for iteration in range(1, MAX_BEAD_REVIEW_ITERATIONS + 1):
        log_step(f"Bead review iteration {iteration}/{MAX_BEAD_REVIEW_ITERATIONS}")

        if dry_run:
            log_info("[dry-run] Would run bead-review in fresh session")
            return

        # Fresh session for review
        review_prompt = (
            f"Load the /bead-review skill. "
            f"Review BEADS.md at {ctx.beads_path} against the TDD at {ctx.tdd_path}. "
            f"The project slug is '{ctx.project_slug}'. "
            f"Update BEADS_LEDGER.md at {ctx.beads_ledger_path}"
        )
        pi_oneshot(review_prompt, cwd=str(ctx.cwd))

        # Parse verdict
        verdict = parse_bead_verdict(ctx)
        log_info(f"Bead review verdict: {verdict}")

        if verdict == BEAD_APPROVED:
            log_step("Beads approved! ✓")
            return

        if verdict in ("HAS_BLOCKERS", "HAS_FINDINGS"):
            log_warn(f"Bead fixes needed (iteration {iteration})")

            if iteration >= MAX_BEAD_REVIEW_ITERATIONS:
                log_error(f"Max bead review iterations ({MAX_BEAD_REVIEW_ITERATIONS}) reached. Aborting.")
                sys.exit(1)

            # Fix beads — use a fresh session (bead-fix is mechanical)
            log_step("Running /bead-fix")
            fix_prompt = (
                f"Load the /bead-fix skill. "
                f"Apply fixes from BEADS_LEDGER.md at {ctx.beads_ledger_path} "
                f"to BEADS.md at {ctx.beads_path}. "
                f"Reference TDD at {ctx.tdd_path} as needed."
            )
            pi_oneshot(fix_prompt, cwd=str(ctx.cwd))
        else:
            log_error(f"Unexpected bead verdict: {verdict}")
            sys.exit(1)

    log_error("Bead review loop did not converge")
    sys.exit(1)


def phase_crystallize(ctx: ProjectContext, dry_run: bool = False):
    """Phase 4: Import beads into bd."""
    log_phase("Phase 4: Crystallize")

    if dry_run:
        log_info("[dry-run] Would run create-beads")
        return

    log_step("Running /create-beads")
    pi_oneshot(
        f"Load the /create-beads skill. "
        f"Import BEADS.md at {ctx.beads_path} into bd. "
        f"The project slug is '{ctx.project_slug}'.",
        cwd=str(ctx.cwd),
    )

    # Verify beads were created
    result = subprocess.run(
        ["bd", "list", "--json"],
        capture_output=True, text=True, cwd=str(ctx.cwd),
    )
    if result.returncode == 0:
        try:
            beads = json.loads(result.stdout)
            log_info(f"Beads in bd: {len(beads)}")
        except json.JSONDecodeError:
            log_warn("Could not parse bd list output")
    else:
        log_warn("bd list failed — beads may not have been imported")


def phase_implement(ctx: ProjectContext, max_workers: int, dry_run: bool = False):
    """Phase 5: DAG-aware parallel implementation using worker subagents."""
    log_phase("Phase 5: Implement")

    if dry_run:
        log_info("[dry-run] Would dispatch worker subagents for implementation")
        return

    # Build the implementation prompt for the orchestrator agent
    # This agent will use the subagent tool to dispatch workers in DAG-aware waves
    label = ctx.project_slug

    implement_prompt = f"""You are the implementation orchestrator. Your job is to implement all beads
for the project '{label}' using worker subagents in DAG-aware waves.

## Workflow

1. Run `bd ready -l {label} --json` to find beads with no blockers
2. For each wave of ready beads, dispatch them in parallel using the subagent tool:
   - Use the `worker` agent for each bead
   - Task for each worker: "Implement bead <ID>: <TITLE>. Read the bead details with `bd show <ID>`.
     Follow the specification exactly. Run tests if specified in acceptance criteria.
     When done, close it with `bd close <ID>`."
3. After each wave completes, run `bd ready -l {label} --json` again to find newly unblocked beads
4. Repeat until no more ready beads exist
5. Run `bd list -l {label} --json` and verify all beads are closed

## Rules

- Dispatch at most {max_workers} workers in parallel per wave
- If a worker fails (bead not closed), retry up to {MAX_BEAD_RETRIES} times
- After {MAX_BEAD_RETRIES} failures on the same bead, log the failure and skip it
- Between waves, wait for all workers to complete before dispatching the next wave
- Use `bd show <ID>` to get full bead details before dispatching each worker

## Start now

Run `bd ready -l {label} --json` to begin."""

    pi_oneshot(implement_prompt, cwd=str(ctx.cwd))


# ─── Main ────────────────────────────────────────────────────────────────────

def resolve_context(rough_path: str) -> ProjectContext:
    """Resolve project context from the path to ROUGH.md."""
    path = Path(rough_path).resolve()
    if not path.exists():
        log_error(f"File not found: {path}")
        sys.exit(1)

    project_dir = path.parent
    project_slug = project_dir.name
    cwd = Path.cwd()

    return ProjectContext(
        rough_path=path,
        project_dir=project_dir,
        project_slug=project_slug,
        cwd=cwd,
    )


def main():
    parser = argparse.ArgumentParser(
        description="Lifecycle orchestrator: planning → review → implementation pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )
    parser.add_argument("rough_path", help="Path to ROUGH.md file")
    parser.add_argument(
        "--skip-to",
        choices=[p.value for p in Phase],
        help="Skip to a specific phase (assumes prior phases are done)",
    )
    parser.add_argument("--dry-run", action="store_true", help="Show what would be done without executing")
    parser.add_argument("--max-workers", type=int, default=DEFAULT_MAX_WORKERS, help="Max parallel workers for implementation")
    parser.add_argument("--model", help="Override model for authoring sessions")
    args = parser.parse_args()

    ctx = resolve_context(args.rough_path)
    skip_to = Phase(args.skip_to) if args.skip_to else None

    log_info(f"Project: {ctx.project_slug}")
    log_info(f"Plan dir: {ctx.project_dir}")
    log_info(f"Working dir: {ctx.cwd}")
    if skip_to:
        log_info(f"Skipping to: {skip_to.value}")
    if args.dry_run:
        log_warn("DRY RUN — no actions will be taken")

    # Determine which phases to run
    phases = list(Phase)
    if skip_to:
        start_idx = phases.index(skip_to)
        phases = phases[start_idx:]

    # Start the author RPC session (used for authoring + revisions)
    rpc = None
    needs_rpc = any(p in phases for p in [Phase.AUTHOR, Phase.DESIGN_REVIEW, Phase.BEAD_REVIEW])

    if needs_rpc and not args.dry_run:
        rpc = PiRpcSession(
            cwd=str(ctx.cwd),
            session_name=f"lifecycle-{ctx.project_slug}",
            model=args.model,
        )
        rpc.start()

    try:
        # Phase 1: Author
        if Phase.AUTHOR in phases:
            phase_author(ctx, rpc, dry_run=args.dry_run)

            # Check if Track S (skip rest)
            if ctx.intake_path.exists() and not args.dry_run:
                intake = parse_intake(ctx)
                if intake.track == "S":
                    log_info("Track S — pipeline complete after authoring.")
                    return

        # Phase 2: Design Review
        if Phase.DESIGN_REVIEW in phases:
            phase_design_review(ctx, rpc, dry_run=args.dry_run)

        # Write beads (part of author session, after design approval)
        if Phase.AUTHOR in phases or Phase.DESIGN_REVIEW in phases:
            if Phase.BEAD_REVIEW in phases:  # only write beads if we're going to review them
                phase_write_beads(ctx, rpc, dry_run=args.dry_run)

        # Phase 3: Bead Review
        if Phase.BEAD_REVIEW in phases:
            phase_bead_review(ctx, rpc, dry_run=args.dry_run)

        # Phase 4: Crystallize
        if Phase.CRYSTALLIZE in phases:
            phase_crystallize(ctx, dry_run=args.dry_run)

        # Phase 5: Implement
        if Phase.IMPLEMENT in phases:
            phase_implement(ctx, max_workers=args.max_workers, dry_run=args.dry_run)

        log_phase("Pipeline Complete ✓")

    finally:
        if rpc:
            rpc.stop()


if __name__ == "__main__":
    main()
